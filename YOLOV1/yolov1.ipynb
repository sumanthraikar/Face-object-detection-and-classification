{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7081637,"sourceType":"datasetVersion","datasetId":4079588},{"sourceId":7097812,"sourceType":"datasetVersion","datasetId":4091038}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport sys\nhelper_files_path = '/kaggle/input/face-detection-helper-files'\nsys.path.insert(0,helper_files_path)\n\nimport torch\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torchvision.transforms.functional as FT\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom model import Yolov1\nfrom dataset import Facedataset\nfrom utils import (\n    non_max_suppression,\n    mean_average_precision,\n    intersection_over_union,\n    cellboxes_to_boxes,\n    get_bboxes,\n    plot_image,\n    save_checkpoint,\n    load_checkpoint,\n)\nfrom loss import YoloLoss\n\nseed = 123\ntorch.manual_seed(seed)\n\nLEARNING_RATE = 2e-5\nDEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\nBATCH_SIZE = 16 # 64 in original paper but I don't have that much vram, grad accum?\nWEIGHT_DECAY = 0\nEPOCHS = 100\nNUM_WORKERS = 2\nPIN_MEMORY = True\nLOAD_MODEL = False\nLOAD_MODEL_FILE = \"/kaggle/working/overfit.pth.tar\"\nIMG_DIR = \"/kaggle/input/face-detection-dataset/images\"\nLABEL_DIR = \"/kaggle/input/face-detection-dataset/labels\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-04T13:04:17.348753Z","iopub.execute_input":"2023-12-04T13:04:17.349578Z","iopub.status.idle":"2023-12-04T13:04:19.024983Z","shell.execute_reply.started":"2023-12-04T13:04:17.349545Z","shell.execute_reply":"2023-12-04T13:04:19.024189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Compose(object):\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img, bboxes):\n        for t in self.transforms:\n            img, bboxes = t(img), bboxes\n\n        return img, bboxes\n\n\ntransform = Compose([transforms.Resize((112, 112)), transforms.ToTensor(),])\n\n\ndef train_fn(train_loader, model, optimizer, loss_fn):\n    loop = tqdm(train_loader, leave=True)\n    mean_loss = []\n\n    for batch_idx, (x, y) in enumerate(loop):\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        x = x.permute(0,3,1,2)\n        out = model(x)\n        loss = loss_fn(out, y)\n        mean_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # update progress bar\n        loop.set_postfix(loss=loss.item())\n\n    print(f\"Mean loss was {sum(mean_loss)/len(mean_loss)}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:04:19.026535Z","iopub.execute_input":"2023-12-04T13:04:19.026895Z","iopub.status.idle":"2023-12-04T13:04:19.035635Z","shell.execute_reply.started":"2023-12-04T13:04:19.026868Z","shell.execute_reply":"2023-12-04T13:04:19.034704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_dataset = Facedataset(\n#     transforms=transform,\n#     image_dir=IMG_DIR,\n#     label_dir=LABEL_DIR,\n# )\n# x,y = train_dataset[0]\n# print(x.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:04:19.036690Z","iopub.execute_input":"2023-12-04T13:04:19.036959Z","iopub.status.idle":"2023-12-04T13:04:19.045315Z","shell.execute_reply.started":"2023-12-04T13:04:19.036935Z","shell.execute_reply":"2023-12-04T13:04:19.044470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Yolov1(split_size=7, num_boxes=2, num_classes=4).to(DEVICE)\noptimizer = optim.Adam(\n    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n)\nloss_fn = YoloLoss()\n\nif LOAD_MODEL:\n    load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n\ntrain_dataset = Facedataset(\n    transforms=transform,\n    image_dir=IMG_DIR,\n    label_dir=LABEL_DIR,\n)\n\ntest_dataset = Facedataset(\n     transforms=transform, image_dir=IMG_DIR, label_dir=LABEL_DIR,\n)\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    pin_memory=PIN_MEMORY,\n    shuffle=True,\n    drop_last=True,\n)\n\ntest_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    pin_memory=PIN_MEMORY,\n    shuffle=True,\n    drop_last=True,\n)\n\nfor epoch in range(EPOCHS):\n#     for x, y in train_loader:\n#        x = x.to(DEVICE)\n#        x = x.permute(0,3,1,2)\n#        for idx in range(8):\n# #            print(model(x).shape)\n#            bboxes = cellboxes_to_boxes(model(x))\n           \n#            bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n#            print(bboxes)\n#            plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes)\n\n#        import sys\n#        sys.exit()\n\n    pred_boxes, target_boxes = get_bboxes(\n        train_loader, model, iou_threshold=0.5, threshold=0.4\n    )\n\n    mean_avg_prec = mean_average_precision(\n        pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n    )\n    print(f\"Train mAP: {mean_avg_prec}\")\n\n    if mean_avg_prec > 0.9:\n       checkpoint = {\n           \"state_dict\": model.state_dict(),\n           \"optimizer\": optimizer.state_dict(),\n       }\n       save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)\n       import time\n       time.sleep(10)\n\n    train_fn(train_loader, model, optimizer, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:04:19.046508Z","iopub.execute_input":"2023-12-04T13:04:19.046777Z","iopub.status.idle":"2023-12-04T13:48:12.951898Z","shell.execute_reply.started":"2023-12-04T13:04:19.046752Z","shell.execute_reply":"2023-12-04T13:48:12.950406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r face_detect_yolov1model.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:48:25.343828Z","iopub.execute_input":"2023-12-04T13:48:25.344742Z","iopub.status.idle":"2023-12-04T13:49:06.028241Z","shell.execute_reply.started":"2023-12-04T13:48:25.344706Z","shell.execute_reply":"2023-12-04T13:49:06.027068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}